{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3980c783",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "\n",
    "import hydra\n",
    "import lightning as L\n",
    "import torch\n",
    "from lightning.pytorch.callbacks import (\n",
    "    EarlyStopping,\n",
    "    LearningRateMonitor,\n",
    "    ModelCheckpoint,\n",
    ")\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from omegaconf import DictConfig\n",
    "from src.data_module import DecathlonDataModule\n",
    "#from src.model import DecathlonModel\n",
    "from src.utils import generate_run_id\n",
    "from monai.networks.nets import SegResNet\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5cf1d770",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "import torch\n",
    "from monai.losses import DiceLoss\n",
    "from monai.networks.nets import DynUNet\n",
    "from monai.networks.layers import Norm\n",
    "from monai.metrics import compute_generalized_dice\n",
    "from monai.inferers import sliding_window_inference\n",
    "\n",
    "\n",
    "class DecathlonModel(L.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        learning_rate: float = 3e-4,\n",
    "        use_scheduler: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.learning_rate = learning_rate\n",
    "        self.use_scheduler = use_scheduler\n",
    "\n",
    "        # Define the model\n",
    "        self._model = DynUNet(\n",
    "            spatial_dims=3,\n",
    "            in_channels=1,\n",
    "            out_channels=1,\n",
    "            kernel_size=[3, 3, 3, 3, 3, 3],\n",
    "            strides=[1, 2, 2, 2, 2, 2],\n",
    "            upsample_kernel_size=[2, 2, 2, 2, 2, 2],\n",
    "            norm_name=Norm.BATCH,\n",
    "            deep_supervision=False,\n",
    "        )\n",
    "\n",
    "        # Define the loss function\n",
    "        self.criterion = DiceLoss(to_onehot_y=True, softmax=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch[\"image\"], batch[\"label\"]\n",
    "        logits = self.forward(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    # Define inference method\n",
    "    def _inference(self, input):\n",
    "        def _compute(input):\n",
    "            return sliding_window_inference(\n",
    "                inputs=input,\n",
    "                roi_size=(128, 128, 128),\n",
    "                sw_batch_size=1,\n",
    "                predictor=self,\n",
    "                overlap=0.5,\n",
    "            )\n",
    "\n",
    "        VAL_AMP = True\n",
    "        if VAL_AMP:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                return _compute(input)\n",
    "        else:\n",
    "            return _compute(input)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch[\"image\"], batch[\"label\"]\n",
    "        logits = self.forward(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        y_pred = self._inference(x)\n",
    "        dice = compute_generalized_dice(y_pred, y)\n",
    "        dice = dice.mean() if len(dice) > 0 else dice\n",
    "        self.log(\"val_loss\", loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"val_dice\", dice, on_step=True, on_epoch=True, prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            self.parameters(), lr=self.learning_rate, weight_decay=0.05\n",
    "        )\n",
    "\n",
    "        configuration = {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"monitor\": \"val_loss\",  # monitor validation loss\n",
    "        }\n",
    "\n",
    "        if self.use_scheduler:\n",
    "            # Add lr scheduler\n",
    "            scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=20)\n",
    "            configuration[\"lr_scheduler\"] = scheduler\n",
    "\n",
    "        return configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9c3672cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    # generate unique run id based on current date & time\n",
    "    run_id = generate_run_id()\n",
    "\n",
    "    # Seed everything for reproducibility\n",
    "    L.seed_everything(42, workers=True)\n",
    "    torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "    # Initialize DataModule\n",
    "    dm = DecathlonDataModule(\n",
    "        root_dir='./data',\n",
    "        task=\"Task06_Lung\",\n",
    "        batch_size=1,\n",
    "        num_workers=3,\n",
    "        seed=42\n",
    "    )\n",
    "    dm.setup()\n",
    "\n",
    "    # Init model from datamodule's attributes\n",
    "    model = DecathlonModel(\n",
    "        # num_classes=dm.num_classes,\n",
    "        learning_rate= 3e-1,\n",
    "        use_scheduler= True,\n",
    "    )\n",
    "\n",
    "    # Init logger\n",
    "    logger = TensorBoardLogger(save_dir='logs', name=\"\", version=run_id)\n",
    "    # Init callbacks\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor=\"val_loss\",\n",
    "        mode=\"min\",\n",
    "        save_top_k=2,\n",
    "        dirpath=join(' artifacts/checkpoints', run_id),\n",
    "        filename=\"{epoch}-{step}-{val_loss:.2f}-{val_dice:.2f}\",\n",
    "    )\n",
    "\n",
    "    # Init LearningRateMonitor\n",
    "    lr_monitor = LearningRateMonitor(logging_interval=\"step\")\n",
    "\n",
    "    # early stopping\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=10,\n",
    "        verbose=True,\n",
    "        mode=\"min\",\n",
    "    )\n",
    "\n",
    "    # Initialize Trainer\n",
    "    trainer = L.Trainer(\n",
    "    max_epochs=10,\n",
    "    accelerator=\"auto\",\n",
    "    devices=\"auto\",\n",
    "    logger=logger,\n",
    "    callbacks=[checkpoint_callback, lr_monitor, early_stopping],\n",
    "    precision=16,  # Enable mixed precision training\n",
    ")\n",
    "\n",
    "\n",
    "    # Train the model\n",
    "    trainer.fit(model, dm)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "46d05054",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-05 16:29:24,736 - INFO - Verified 'Task06_Lung.tar', md5: 8afd997733c7fc0432f71255ba4e52dc.\n",
      "2024-07-05 16:29:24,737 - INFO - File exists: C:\\Users\\matij\\Downloads\\lung-tumours-segmentation-main\\data\\Task06_Lung.tar, skipped downloading.\n",
      "2024-07-05 16:29:24,741 - INFO - Non-empty folder exists in C:\\Users\\matij\\Downloads\\lung-tumours-segmentation-main\\data\\Task06_Lung, skipped extracting.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79adeb93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61c09bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380be953",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
